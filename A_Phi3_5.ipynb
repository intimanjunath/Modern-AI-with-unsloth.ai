{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Summarization"
      ],
      "metadata": {
        "id": "v702amKvohpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Install dependencies (if not already done)"
      ],
      "metadata": {
        "id": "JeaKKJTPmmcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q unsloth accelerate peft trl transformers bitsandbytes datasets"
      ],
      "metadata": {
        "id": "V2lFn51_mZyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: Load Phi-3.5 Mini with Unsloth"
      ],
      "metadata": {
        "id": "yMgsbzXcm0Ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/phi-3-mini-4k-instruct-bnb-4bit\",\n",
        "    max_seq_length = 2048,\n",
        "    dtype = torch.float16,\n",
        "    load_in_4bit = True,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345,
          "referenced_widgets": [
            "ae403966301049a0b992e52bd4034c29",
            "eaf8b60461eb4d66967702bca9c8d541",
            "5fc1e349c0484530bb82cc32c6f69ee9",
            "b0b6f26fcd084eb3bbb048141425be42",
            "24d71ede909c4f94b600aa3617f0dcfe",
            "b2516b23df474d9ea215fe13736d8844",
            "50e7895a424847b9b7d7da449afb239d",
            "d3f639f6b43d49d5bb761732a6a05610",
            "01dd3c6450be4163b27cd944cbb70906",
            "31b380b257e042d0838e96d8c9e0a3d4",
            "8bdcc5f221cb481c9cd632a4117774c9",
            "5627c3723f8f47798a0d007044dcc1db",
            "9103da93e27e4e1ab460b75e5891b047",
            "99254b6f93544be88b9ea1b8b37e95bb",
            "58651a3ba7c749a4b277f20666141f81",
            "f42e22f112c743cfa9d7e1b313cc21f4",
            "c8046d26918e4ad1840ac824abf55f8f",
            "53eeb5207fb0400f9ed07f60b23fa597",
            "513b83c5197f4e92ac2f0a8ff505f0da",
            "80369ad866a046039ae57767a02135fb",
            "96700560db7149caa8b279b527668b71",
            "482e92df02004441bca8563d35dcddff",
            "d4310f9109934ad6b629d3ae73a1fd33",
            "1778f430d6d8479ebfe4320f7468b4e2",
            "ab5085bf7ffa4db18994d47b6a1b1837",
            "a16196ec09ff4da88d5e18ab7a0ac08d",
            "ce709aac59744ddd97f2c4c5ed845f1f",
            "398aa3356f7e4acb823b8fdb4b26390b",
            "02f30ba1b9b141cab5cd90fb7798eb43",
            "71a94551ce2c4daf97a32c39c342bca7",
            "2fe29e065051477590675fd7e040a3e6",
            "1003446f220a4d2aaa65aba53007b7d2",
            "5166ba77f26a42ecbaea85800ee38fdf",
            "169a25e0c8854f8aaf2f256ee7648739",
            "7d7c124f984441d09a4c089db9fdae75",
            "4b7e85057bfd4d2db03be40b550d770f",
            "fa4a7b1a8d4d40429caa941870dca032",
            "cb1263c53f464b75ba1df480714f36cd",
            "38533529662447e79c1b463213db586d",
            "1262bf9deb0c4dd7a4c68c7c6053c3b7",
            "91ac11206c664d6d9253e3ab52eb66ab",
            "58fb250ed34d42679f2f92ede9a29800",
            "ca8fda8b42fc4effa12305246db40f45",
            "05d1200cc6cc4aa0a337cbda6254b5be",
            "c3d8c6785b0a44c787602df753e746f7",
            "6fc9c2706c1b4ccfa1328e156c376f5e",
            "f401262cc8ba4170bad197985641ef64",
            "2f0debe0d5bd4248968aa33cab64ffc5",
            "9f3b97ddd29547378d6fda1276238ac6",
            "270f52950ec747caa7d569e786891c0b",
            "96dedec913bd46b1b2a1c1586c225294",
            "f9079559a6f441e8a78c8a976e5a7af4",
            "3649568d3a7345089b505132fa834230",
            "9a723f79e8ce4466b8bbd665db9c667c",
            "93eec07ae5864719b4c32fa8cb22c95e",
            "e8ff77bff4a445ec974c97a8c1f1a67d",
            "6ed561cc09c8495eb2764acd87def8ee",
            "77d6c26c187d4b9b9fd084274ed8790e",
            "5dcbb7f393574d908cea9f24cecd2c68",
            "d19de8878b0e49499dc4e0acf341e134",
            "a670912c8dee4aacbff4f79b66a0a95a",
            "b0a9a2e51c4a41638b5cb1f05197d21c",
            "6c23ee3ae15f484c97ada8cbd5edc70f",
            "90129e26423542348e8872ec0c4fa533",
            "7a4d11bae7d94e0fbd8649d8344b0610",
            "eddbd82bed324c6d95636a4a27a38eec",
            "cf9fbf7bec1041b6932081c0e21449fe",
            "1bbeaa88b8be4ae891977df09b2cbb30",
            "f5cdd7fbe18145df837e31491c69b49a",
            "2ef47996002c46f2bc2c8121fccc0993",
            "36088faba5a044bbb48d7279f1227e42",
            "41f12f47a1ab4723b619e27cdc29f8eb",
            "ee6b1d1a0cd34a53a6ef5e1c0018552a",
            "881e3bed35e24a9994322897469344d2",
            "1adc7517a59046a3b5af12d9ef63eadc",
            "b95e53b7091641bd8aafb004af42bd69",
            "f66b5bdb9fb64b1280e310a4adf37747"
          ]
        },
        "id": "aKH7zTmfmpwG",
        "outputId": "19b34baf-3c9d-4cbd-8ece-806370e6a8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Mistral patching. Transformers: 4.50.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae403966301049a0b992e52bd4034c29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/194 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5627c3723f8f47798a0d007044dcc1db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4310f9109934ad6b629d3ae73a1fd33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "169a25e0c8854f8aaf2f256ee7648739"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3d8c6785b0a44c787602df753e746f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/458 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8ff77bff4a445ec974c97a8c1f1a67d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf9fbf7bec1041b6932081c0e21449fe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Create a Mini Summarization Dataset"
      ],
      "metadata": {
        "id": "Sj84BVXom3nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "summary_data = [\n",
        "    {\n",
        "        \"instruction\": \"Summarize the following text:\",\n",
        "        \"input\": \"Artificial Intelligence is rapidly evolving and influencing various industries such as healthcare, finance, and education. It is being used for predictive analytics, automation, and personalized services.\",\n",
        "        \"output\": \"AI is transforming industries through automation, analytics, and personalization.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Summarize the following text:\",\n",
        "        \"input\": \"The Earth revolves around the Sun once every 365.25 days, which results in the progression of seasons. This orbital movement, combined with the planet's tilt, causes seasonal changes.\",\n",
        "        \"output\": \"Earth's orbit and tilt cause seasonal changes over a year.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Summarize the following text:\",\n",
        "        \"input\": \"Cloud computing provides on-demand access to computing resources. It enables businesses to scale operations efficiently and reduce the cost of maintaining physical infrastructure.\",\n",
        "        \"output\": \"Cloud computing offers scalable resources and lowers infrastructure costs.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "dataset = Dataset.from_list(summary_data)\n"
      ],
      "metadata": {
        "id": "b-oZGnd6mx2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4: Format the Data (chat-style)"
      ],
      "metadata": {
        "id": "4EfWENpkm74_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_summary(example):\n",
        "    prompt = f\"\"\"<|user|>\\n{example['instruction']} {example['input']}<|end|>\\n<|assistant|>\\n{example['output']}<|end|>\"\"\"\n",
        "    example[\"text\"] = prompt\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(format_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c9e07d72ca6c44db918d0094b34bfc60",
            "828c30d1092941edaf646100f78d9f5c",
            "617a5c2dc0e34e71b7e2eaa75d79ccc6",
            "5e10076043d6410d95d777dd1bab1c3b",
            "9390c638a7a847f6bcbd5870c7e8331c",
            "abfb127ce1f04a1d8e146613e5b983e1",
            "e4596ce5b19b4041a1c824ed882af410",
            "f75404bee1424163b85d400a0f385490",
            "7d2aac8d4f414e0e9ab2dcc787b06073",
            "1302a202c54749ad900e99a9247abad6",
            "6809e7a862384f47bd91290fc8ceb095"
          ]
        },
        "id": "aiUXgop6mwuB",
        "outputId": "7073d6da-890a-4e96-983a-f5eaa6e4fcd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9e07d72ca6c44db918d0094b34bfc60"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 5: Apply LoRA for Fine-Tuning"
      ],
      "metadata": {
        "id": "0A297LdJnA6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_training(model)\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    use_gradient_checkpointing=True,\n",
        "    random_state=42,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None,\n",
        ")\n"
      ],
      "metadata": {
        "id": "2oCwNQzGmumX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 6: Set Training Arguments & Train"
      ],
      "metadata": {
        "id": "uuDO0Ol9nD5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    warmup_steps=5,\n",
        "    max_steps=30,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=1,\n",
        "    output_dir=\"phi3.5_summary_lora\",\n",
        "    save_strategy=\"no\"\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=2048,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "02e5d152a3a44da3970d1e052a4b6f6e",
            "7f049aeb266d4b1fb344e0ae405ff45b",
            "a2766793283449dc9999493f25507737",
            "9567ce86c0a74f4fbf84473317155dcb",
            "72f4a6e198cf40d891305beb9e3a4a74",
            "f3b14341dd7948c8ba6a9f3b50aeb5f4",
            "b35318d69ea842db96d5806ad6d308bc",
            "e1215c4d842447798dc504cd72ef4007",
            "6d9ee24a8be64ac8bcdae916a6111feb",
            "cd3ebfb9f13946bfabc7c2f106a65c7a",
            "7d20840051444b88836d3c162b56ff6a"
          ]
        },
        "id": "lUim6IkkmtCA",
        "outputId": "57c16ff8-a5c1-46b9-cb5a-66990a20394a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/3 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02e5d152a3a44da3970d1e052a4b6f6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 3 | Num Epochs = 30 | Total steps = 30\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 12,582,912/4,000,000,000 (0.31% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 00:44, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.420700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.420700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.399300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.332300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.224200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.074800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.898300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.755700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.644500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.541400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.443000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.270900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.201000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.141200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.088200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.052900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.034200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.026200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.022700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.022200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.021600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.018700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.019400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.019900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.019400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.018400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.018200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.017900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.017600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=30, training_loss=0.41784851110229887, metrics={'train_runtime': 50.6874, 'train_samples_per_second': 4.735, 'train_steps_per_second': 0.592, 'total_flos': 141077063301120.0, 'train_loss': 0.41784851110229887})"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 7: Inference (Summarization)"
      ],
      "metadata": {
        "id": "qYJjfQiDnIRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"<|user|>\n",
        "Summarize the following text: The Amazon rainforest plays a crucial role in regulating the Earth's climate. It stores vast amounts of carbon and supports diverse ecosystems.<|end|>\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "eos_token_id = tokenizer.convert_tokens_to_ids(\"<|end|>\") or tokenizer.eos_token_id\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=100,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        eos_token_id=eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "decoded = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "# Extract the assistant's summary\n",
        "if \"<|assistant|>\" in decoded:\n",
        "    response = decoded.split(\"<|assistant|>\")[-1].split(\"<|\")[0].strip()\n",
        "    print(\"=== Summary ===\\n\")\n",
        "    print(response)\n",
        "else:\n",
        "    print(\"⚠️ Could not parse output. Raw result:\\n\", decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmnUxyWxmrim",
        "outputId": "5706adc1-c515-4550-9b79-919cb60e7417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Summary ===\n",
            "\n",
            "The Amazon regulates climate, stores carbon, and supports biodiversity.\n"
          ]
        }
      ]
    }
  ]
}