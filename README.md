## Part A: Full Finetuning with a small model
I have fine-tune a variety of open-weight LLMs using Unsloth AI for different specialized tasks:

- **Llama 3.1 (8B)** â€“ Code generation & debugging assistant  
  ðŸ“„ [Colab Notebook](https://drive.google.com/file/d/1dY0nmvW5cqDh9iT8q_y8zG_0VT10KaqO/view?usp=sharing)  
- **Mistral NeMo (12B)** â€“ Customer-support chat agent  
  ðŸ“„ [Colab Notebook](https://drive.google.com/file/d/1I-Axx7zxIjbhxY4_btgTXZt9NpnnLfCe/view?usp=sharing)  
- **Gemma 2 (9B)** â€“ Human-like conversational AI  
  ðŸ“„ [Colab Notebook](https://drive.google.com/file/d/1DBtPX4Jvc2sI_76sn3z1J4ZoURhyCdPG/view?usp=sharing)  
- **Phi-3 (medium)** â€“ Math-based reasoning & problem solving  
  ðŸ“„ [Colab Notebook](https://drive.google.com/file/d/13GHh5p_3D-o_M2EJ4SYgh28_la16ownR/view?usp=sharing)  

## Part B: Continued Pretraining on LORA parameter(smollm-135m)
- **Purpose:** Adapt to handle Hindi text by unsupervised continuation of its language model pretraining.  
- ðŸ“„ [Open in Colab](https://drive.google.com/file/d/1TN4YXabGjhG6VA4X5kl9lt6Vx5W9BIT-/view?usp=sharing)

---

## Part C: Reinforcment learning where both input and preferred and rejected output is present 

---

## Part D: reinformcement learning with grpo


---

## Part E: Continued pretraining from Checkpoint  

---

## Part F: Mental-Health Support Chatbot  
**Model:** Phi-3 Mini  
- **Scope:** Fine-tune for empathetic, safe mental-health conversations, including dataset sourcing and safety filtering.  
- ðŸ“„ [Open in Colab](https://drive.google.com/file/d/1q1-I7Gg5JXCtd7-9PAbGfBmNdBZZ9xWu/view?usp=sharing)

---

## Part G: Export & Inference with Ollama  
**Model:** Llama 3  
- **Goal:** Convert your LoRA adapter into a GGUF format and run live inference via Ollama.  
- ðŸ“„ [Open in Colab](https://drive.google.com/file/d/1OHtx8wDypC_pJb5RoWIsjruUq5acv0Tb/view?usp=sharing)

---

YouTube Demo explaning Youtube : 
