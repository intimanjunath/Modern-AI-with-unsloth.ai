{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Conversational"
      ],
      "metadata": {
        "id": "Xiu_8hBhmG27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install requirements"
      ],
      "metadata": {
        "id": "5XWuuy4bXo9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q unsloth accelerate peft trl transformers bitsandbytes datasets"
      ],
      "metadata": {
        "id": "ZRu1kmt2Xm1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Mistral Model with Unsloth"
      ],
      "metadata": {
        "id": "zLzfNrEpXpgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/mistral-7b-bnb-4bit\",  # closest Unsloth-compatible Mistral variant\n",
        "    max_seq_length = 2048,\n",
        "    dtype = torch.float16,\n",
        "    load_in_4bit = True,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "2ff5faea03084a43b8e51fd3854f46c6",
            "61b0d60c4f994f01812cc0c7329c9315",
            "0a098d4f97354a48a67a54a1c3bf8dc7",
            "f561eb3765d24622ae5bfdca5ca30f5b",
            "8066f440b4d640ecabecbafe67222f4c",
            "7f6dbd31d9ab482cb6c52b08e58114cd",
            "c55db5d6223f4760b634673d7f5aebd1",
            "8351c81287e6449f8dc80abddfac8f2a",
            "103289b6d43f4915abefd6466a2e8324",
            "58a628150a7c4d31aef0b6ecb9dbe2aa",
            "8cb5b80d19044bd1ad2a8d1c519de3a8",
            "039dd1b24dfd4be4812251496ea17a11",
            "32ab37af15d84f06b94111c141120f01",
            "8a2cdef4ea054bad904eefba521c6540",
            "a0523e0093a54f6e81a3ee502fcf7f38",
            "4587099b30944baeb3503d01283eabb0",
            "f700076f2de44b89bb100a7bdacdbc26",
            "65d0b2a71ed84e1c825799ab8eb2dbf6",
            "9a315dd5450f4c64baa3ebd8f08a0238",
            "149f2e1d32cb441a9cc612aa2f887ac3",
            "72bee4b9791a4c11b3cf9f1176e0d13d",
            "d8973e6f33e245debc982d57df553300",
            "9a5a8624695f48c78a7510d7b0a93a54",
            "3119d54ffef94632a37c67fa4675a9ff",
            "c6bcabd665154fffa72a95cf0fc82da5",
            "5ff08777448f4c4894bf28b00ef0edbe",
            "7d2822917e6f4a0d901325bbd81cd0de",
            "86a3ee77b072424899c33527ec9bd748",
            "89f0855ccc2a4fab816db68f4a84b05d",
            "226c069bd4094ae598a4bffa481a11fa",
            "991fa312f9b54deda9ace934b414e4e1",
            "2cdc60ecb3714b9083c3b3adb57b8776",
            "4d0fcbcaab8444f6827429dc50d447d3",
            "e574554f48bb471b9e52ee9f5b6887b4",
            "c59ea65759b54bd1a2e3bf70cee52b35",
            "2522f7ec06df40828ac176577add7b57",
            "0aa156a7f33b436e90873544ad5bb39e",
            "b75d39193f034844bbb4c81f9a63937d",
            "f2b17718964740a7ac8d2173f3b605a4",
            "05524c1dae4a496c82ad9b97ac82270e",
            "c32c4b8e3f6747378a9027829e495a68",
            "963bfc5f155c4285935f057834a20322",
            "80a85f4c823d4904921ba54090be4556",
            "5e8d7aae72744d738995a8695a0d0edf",
            "33694f5fd7dc448491afc9e73818b0e7",
            "36f6b827d709418aa62c83390cacc490",
            "53566b613f3244f396b67937ca384e19",
            "1774371f490a4885847407f2b8e621f1",
            "c6d438c858d54ff8839ad3019c09159d",
            "f3ddbb284ba749debc5f8ef7fa7772b8",
            "a738c2b534eb4e19ab5b41ca6a275cec",
            "2a3ee78d4d7a4432bc5ab45c1731f0f4",
            "592e8e75cade4e8280188008a36f9ce6",
            "49dac4b3b409445282f70be2e0790b61",
            "7570ccd6b7c143a88a78db72ceceeaf6",
            "5ffb99aae29249e1a1a80f3d14af0479",
            "862bcfbdc24c438287f3accfc595742b",
            "2fad55f383534090b8d4e167c622f171",
            "30cf9cfdefed4f93bd33a12929c6dd92",
            "3ce1e1413d1549638a137c1d7f9d310f",
            "8376ad3836e14a26a50ee048c094cdb4",
            "69e22cfc4f7a48b49f1814a991b4668f",
            "7c515acf7ffb4e2397947d62164da69c",
            "d77c5d6d419c461486cacee59ad473ad",
            "58f2e2e9bbc94fc3aa97725f2c8e6a68",
            "161e3e8bc94443109a6a1190806eb07f"
          ]
        },
        "id": "H4be03eTXm4C",
        "outputId": "b0ed69e2-b3b0-48a3-f9e1-2bd96efb593c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Mistral patching. Transformers: 4.50.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/4.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ff5faea03084a43b8e51fd3854f46c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/155 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "039dd1b24dfd4be4812251496ea17a11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a5a8624695f48c78a7510d7b0a93a54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e574554f48bb471b9e52ee9f5b6887b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33694f5fd7dc448491afc9e73818b0e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ffb99aae29249e1a1a80f3d14af0479"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a Small Chat Dataset (Conversational)"
      ],
      "metadata": {
        "id": "7199AdBvXqCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "chat_data = [\n",
        "    {\n",
        "        \"instruction\": \"Hi there, how can I improve my sleep?\",\n",
        "        \"input\": \"\",\n",
        "        \"output\": \"Hello! Here are a few tips: maintain a consistent sleep schedule, avoid screens before bed, and create a calming bedtime routine.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Can you explain what a transformer model is in simple terms?\",\n",
        "        \"input\": \"\",\n",
        "        \"output\": \"Sure! A transformer is a type of neural network that processes input data in parallel using attention mechanisms to understand relationships between words or tokens.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What's a good way to learn Python as a beginner?\",\n",
        "        \"input\": \"\",\n",
        "        \"output\": \"Start with small projects, follow tutorials on websites like freeCodeCamp or W3Schools, and practice coding every day. Consistency is key!\"\n",
        "    },\n",
        "]\n",
        "\n",
        "dataset = Dataset.from_list(chat_data)"
      ],
      "metadata": {
        "id": "HtmtHMw_Xm6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Format Chat Prompts"
      ],
      "metadata": {
        "id": "jG-qNg1NXqaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_chat(example):\n",
        "    prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "{example[\"instruction\"]}{example[\"input\"]}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "{example[\"output\"]}<|eot_id|>\"\"\"\n",
        "    example[\"text\"] = prompt\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(format_chat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c57e88908d0245e9aad72e2072c74e0a",
            "3686738f19f64864a41b78012d80deac",
            "ac3499a9288242188a770e88147a4b13",
            "a21bbe149ae9479c96a82e9e05656375",
            "5701476fc804411a9681588462e5fbd2",
            "e789f6d6bd0041148c22a3458f973fc6",
            "4e2228210b374dc59e5a45be2d532c74",
            "3537a5350cb34fc19160494fe9b19464",
            "125e8e6d0f884a959a41904622d23797",
            "8b717f1253de45a3be40ec4d7c7a8e15",
            "fdcb4b6675b6412e8e848eab419826b2"
          ]
        },
        "id": "Ffun1sfIXm9P",
        "outputId": "40635b07-ddf4-4ef2-fc7a-a5aebf22daaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c57e88908d0245e9aad72e2072c74e0a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare LoRA for Training"
      ],
      "metadata": {
        "id": "g6nXmfPzXq0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_training(model)\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    use_gradient_checkpointing=True,\n",
        "    random_state=42,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None,\n",
        ")"
      ],
      "metadata": {
        "id": "7fA3weB2Xm_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Setup"
      ],
      "metadata": {
        "id": "SZwxS2LyXrl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    warmup_steps=5,\n",
        "    max_steps=30,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=1,\n",
        "    output_dir=\"mistral_chat_lora\",\n",
        "    save_strategy=\"no\"\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=2048,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5179656f10e74f09a324288d0854d6fe",
            "a857be266f164f028a05fe693a52898e",
            "2c4a0e7c1db048ac8182bc9fec389c9a",
            "43d14a44ecc349cc837c435ebb657e37",
            "def530bda561440a9b5b3eb81d6e4705",
            "ad1c60f1a24e4b2f9130a5f1fad8f9b0",
            "05482344387e42b496c6e51437d3769a",
            "e79c383cbc42424780a57ef7fa03d46b",
            "640c3fd211864a0ca002739f6cad45ae",
            "0725142b28084e58a47955db3feaf085",
            "1abb8de56dd64ecdaea92c47543b1412"
          ]
        },
        "id": "cy4L6eJaXnCO",
        "outputId": "d6f6b777-a502-48ad-dabd-66a522ed338e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/3 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5179656f10e74f09a324288d0854d6fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 3 | Num Epochs = 30 | Total steps = 30\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 13,631,488/7,000,000,000 (0.19% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 00:53, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.934700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.934800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.702400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.424500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.115600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.828500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.579900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.409900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.286500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.188900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.138200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.168800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.098600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.092900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.079400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.077700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.067800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.072300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.070300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.065700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.065700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.065300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.064400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.063800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.064100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.064100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.063700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.063600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.063300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.063500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=30, training_loss=0.39929490561286607, metrics={'train_runtime': 56.0307, 'train_samples_per_second': 4.283, 'train_steps_per_second': 0.535, 'total_flos': 414847498936320.0, 'train_loss': 0.39929490561286607})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference Block (Clean)"
      ],
      "metadata": {
        "id": "Ge3CFtgIXr-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "Can you tell me how to stay productive when working from home?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "eos_token_id = tokenizer.convert_tokens_to_ids(\"<|eot_id|>\") or tokenizer.eos_token_id\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=300,\n",
        "        temperature=0.5,\n",
        "        top_p=0.9,\n",
        "        do_sample=True,\n",
        "        eos_token_id=eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "decoded = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "# Extract the assistant's response\n",
        "if \"<|start_header_id|>assistant<|end_header_id|>\" in decoded:\n",
        "    response = decoded.split(\"<|start_header_id|>assistant<|end_header_id|>\")[1]\n",
        "    print(\"=== Assistant Response ===\\n\")\n",
        "    print(response.split(\"<|\")[0].strip())\n",
        "else:\n",
        "    print(\"⚠️ Could not find assistant response. Raw output:\\n\", decoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW0ZsnlKXnEk",
        "outputId": "deab57d4-2ff8-4551-9fab-c0bd1e24d7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Assistant Response ===\n",
            "\n",
            "Sure! Here are a few tips: maintain a routine, take breaks, and avoid distractions.\n"
          ]
        }
      ]
    }
  ]
}